[
  {
    "objectID": "01_Openai_api.html",
    "href": "01_Openai_api.html",
    "title": "Uso bÃ¡sico de la API de OpenAI",
    "section": "",
    "text": "ConfiguraciÃ³n Inicial\nEste tutorial muestra cÃ³mo usar la API de OpenAI con la biblioteca oficial\nImportamos las librerÃ­as necesarias y cargamos las variables de entorno.\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()  # Carga el archivo de las variables de entorno\n\napi_key = os.getenv('OPENAI_API_KEY')\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Uso bÃ¡sico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#solicitud-a-la-api",
    "href": "01_Openai_api.html#solicitud-a-la-api",
    "title": "Uso bÃ¡sico de la API de OpenAI",
    "section": "Solicitud a la API",
    "text": "Solicitud a la API\nUsamos el modelo gpt-4o-mini para enviar un mensaje y obtener una respuesta.\n\ncompletion = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[\n        {\n            'role': 'user',\n            'content': 'Â¡Hola! Â¿Me ayudas a aprender sobre la API de OpenAI'\n        }\n    ]\n)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Uso bÃ¡sico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#ver-la-respuesta",
    "href": "01_Openai_api.html#ver-la-respuesta",
    "title": "Uso bÃ¡sico de la API de OpenAI",
    "section": "Ver la respuesta",
    "text": "Ver la respuesta\nExtraemos el contenido de la respuesta del asistente.\n\ncompletion.choices[0].message\n\nChatCompletionMessage(content='Â¡Hola! Claro que sÃ­, estarÃ© encantado de ayudarte a aprender sobre la API de OpenAI. La API de OpenAI proporciona acceso a los modelos de lenguaje de OpenAI, como GPT-3 y GPT-4, entre otros. AquÃ­ tienes un resumen para empezar:\\n\\n### 1. **Â¿QuÃ© es la API de OpenAI?**\\n   - Es una interfaz que permite a los desarrolladores interactuar con los modelos de IA de OpenAI.\\n   - Se puede usar para tareas como generaciÃ³n de texto, traducciÃ³n, respuesta a preguntas, y mÃ¡s.\\n\\n### 2. **Â¿CÃ³mo funciona?**\\n   - EnvÃ­as una solicitud HTTP que incluye tu mensaje o prompt.\\n   - La API procesa el input y devuelve una respuesta generada por el modelo.\\n\\n### 3. **Inicio RÃ¡pido:**\\n   - **Registro:** Necesitas registrarte en el sitio de OpenAI y obtener una clave de API.\\n   - **LibrerÃ­a:** Puedes usar bibliotecas como `requests` (en Python) para hacer llamadas a la API.\\n\\n### 4. **Ejemplo de CÃ³digo (Python):**\\n```python\\nimport openai\\n\\nopenai.api_key = \\'tu_clave_de_api\\'\\n\\nrespuesta = openai.ChatCompletion.create(\\n    model=\"gpt-3.5-turbo\",  # O cualquier modelo que estÃ©s utilizando\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"Hola, Â¿puedes ayudarme con un problema?\"}\\n    ]\\n)\\n\\nprint(respuesta[\\'choices\\'][0][\\'message\\'][\\'content\\'])\\n```\\n\\n### 5. **ParÃ¡metros Clave:**\\n   - **model:** Especifica el modelo a utilizar (ej. \"gpt-3.5-turbo\").\\n   - **messages:** Una lista de mensajes que simulan una conversaciÃ³n, donde cada mensaje tiene un rol (\\'user\\', \\'assistant\\', etc.).\\n   - **max_tokens:** Controla la longitud mÃ¡xima de la respuesta.\\n   - **temperature:** Controla la creatividad en la respuesta (valores entre 0 y 1).\\n\\n### 6. **Costos:**\\n   - La API tiene un costo basado en el nÃºmero de tokens procesados. AsegÃºrate de consultar la pÃ¡gina de precios para obtener detalles.\\n\\n### 7. **Consideraciones:**\\n   - Siempre revisa las polÃ­ticas de uso de OpenAI para asegurarte de que estÃ¡s utilizando la API de manera Ã©tica.\\n   - Trata de optimizar tus prompts para obtener mejores respuestas.\\n\\nSi tienes alguna pregunta especÃ­fica o un Ã¡rea en la que te gustarÃ­a profundizar mÃ¡s, Â¡hÃ¡zmelo saber!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Uso bÃ¡sico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#mostrar-la-respuesta-en-formato-markdown",
    "href": "01_Openai_api.html#mostrar-la-respuesta-en-formato-markdown",
    "title": "Uso bÃ¡sico de la API de OpenAI",
    "section": "Mostrar la respuesta en formato Markdown",
    "text": "Mostrar la respuesta en formato Markdown\nUtilizamos IPyhton para mostrar el contenido como texto formateado.\n\nfrom IPython.display import display, Markdown\ndisplay(Markdown(completion.choices[0].message.content))\n\nÂ¡Hola! Claro que sÃ­, estarÃ© encantado de ayudarte a aprender sobre la API de OpenAI. La API de OpenAI proporciona acceso a los modelos de lenguaje de OpenAI, como GPT-3 y GPT-4, entre otros. AquÃ­ tienes un resumen para empezar:\n\n1. Â¿QuÃ© es la API de OpenAI?\n\nEs una interfaz que permite a los desarrolladores interactuar con los modelos de IA de OpenAI.\nSe puede usar para tareas como generaciÃ³n de texto, traducciÃ³n, respuesta a preguntas, y mÃ¡s.\n\n\n\n2. Â¿CÃ³mo funciona?\n\nEnvÃ­as una solicitud HTTP que incluye tu mensaje o prompt.\nLa API procesa el input y devuelve una respuesta generada por el modelo.\n\n\n\n3. Inicio RÃ¡pido:\n\nRegistro: Necesitas registrarte en el sitio de OpenAI y obtener una clave de API.\nLibrerÃ­a: Puedes usar bibliotecas como requests (en Python) para hacer llamadas a la API.\n\n\n\n4. Ejemplo de CÃ³digo (Python):\nimport openai\n\nopenai.api_key = 'tu_clave_de_api'\n\nrespuesta = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",  # O cualquier modelo que estÃ©s utilizando\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hola, Â¿puedes ayudarme con un problema?\"}\n    ]\n)\n\nprint(respuesta['choices'][0]['message']['content'])\n\n\n5. ParÃ¡metros Clave:\n\nmodel: Especifica el modelo a utilizar (ej. â€œgpt-3.5-turboâ€).\nmessages: Una lista de mensajes que simulan una conversaciÃ³n, donde cada mensaje tiene un rol (â€˜userâ€™, â€˜assistantâ€™, etc.).\nmax_tokens: Controla la longitud mÃ¡xima de la respuesta.\ntemperature: Controla la creatividad en la respuesta (valores entre 0 y 1).\n\n\n\n6. Costos:\n\nLa API tiene un costo basado en el nÃºmero de tokens procesados. AsegÃºrate de consultar la pÃ¡gina de precios para obtener detalles.\n\n\n\n7. Consideraciones:\n\nSiempre revisa las polÃ­ticas de uso de OpenAI para asegurarte de que estÃ¡s utilizando la API de manera Ã©tica.\nTrata de optimizar tus prompts para obtener mejores respuestas.\n\nSi tienes alguna pregunta especÃ­fica o un Ã¡rea en la que te gustarÃ­a profundizar mÃ¡s, Â¡hÃ¡zmelo saber!",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Uso bÃ¡sico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#ver-el-rol-del-mensaje",
    "href": "01_Openai_api.html#ver-el-rol-del-mensaje",
    "title": "Uso bÃ¡sico de la API de OpenAI",
    "section": "Ver el rol del mensaje",
    "text": "Ver el rol del mensaje\n\nprint(completion.choices[0].message.role)\n\nassistant",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Uso bÃ¡sico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#conclusiones",
    "href": "01_Openai_api.html#conclusiones",
    "title": "Uso bÃ¡sico de la API de OpenAI",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nEste ejemplo muestra cÃ³mo configurar y hacer un request bÃ¡sico a la API.\nPuedes cambiar el modelo (gpt-4o-mini, gpt-3.5-turbo, etc.) segÃºn tus necesidades.\nEl uso de Markdown en la salida mÃ¡s legible la respuesta.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Uso bÃ¡sico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html",
    "href": "02_Openai_api.html",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "",
    "text": "Objetivo\nEn este tutorial aprenderÃ¡s a:",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#objetivo",
    "href": "02_Openai_api.html#objetivo",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "",
    "text": "Usar un system prompt para dar contexto al asistente.\nRealizar llamadas con humor y estilo especÃ­fico.\nConstruir una conversaciÃ³n con memoria de mensajes anteriores.\nEncapsular la lÃ³gica de interacciÃ³n en una funciÃ³n reutilizable.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#configuraciÃ³n-inicial",
    "href": "02_Openai_api.html#configuraciÃ³n-inicial",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "ConfiguraciÃ³n Inicial",
    "text": "ConfiguraciÃ³n Inicial\nImportamos librerÃ­as necesarias, cargamos la API key desde un .env y creamos un cliente de OpenAI.\n\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\napi_key = os.getenv('OPENAI_API_KEY')\n\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#funciÃ³n-par-enviar-mensajes-con-system_promt",
    "href": "02_Openai_api.html#funciÃ³n-par-enviar-mensajes-con-system_promt",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "FunciÃ³n par enviar mensajes con system_promt",
    "text": "FunciÃ³n par enviar mensajes con system_promt\nEsta funciÃ³n permite enviar un prompt con rol system que define el estilo del asistente.\n\ndef chat_with_system(system_prompt: str, user_prompt: str) -&gt; str:\n    '''Realiza una llamada con system prompt'''\n    try:\n        response = client.chat.completions.create(\n            model='gpt-4o',\n            messages=[\n                {'role': 'system', 'content': system_prompt},\n                {'role': 'user', 'content': user_prompt}\n            ]\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        return f'Error: {str(e)}'",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#ejemplo-de-uso-con-humor-y-acento-argentino",
    "href": "02_Openai_api.html#ejemplo-de-uso-con-humor-y-acento-argentino",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "Ejemplo de uso con humor y acento argentino",
    "text": "Ejemplo de uso con humor y acento argentino\n\nsystem_prompt = '''Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino'''\nuser_prompt = 'algo de borrachos'\nrespuesta = chat_with_system(system_prompt, user_prompt)\n\nprint(f'\\nSystem Prompt: {system_prompt}')\nprint(f'\\nUser Prompt: {user_prompt}')\nprint(f'\\nRespuesta: {respuesta}')\n\n\nSystem Prompt: Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino\n\nUser Prompt: algo de borrachos\n\nRespuesta: Â¡Ah, los borrachos! MirÃ¡, te cuento una historia: estaba un tipo completamente borracho en la puerta de un bar, tratando de llegar a su casa despuÃ©s de una noche de copas. Se acerca un policÃ­a y le pregunta:\nâ€”SeÃ±or, Â¿estÃ¡ usted borracho?\nY el tipo le responde:\nâ€”No oficial, estoy sobrio... sobrio como un juez.\nEl policÃ­a se rÃ­e y le dice:\nâ€”Bueno seÃ±or, entonces dÃ­game quiÃ©n es usted.\nEl borracho lo mira extraÃ±ado y le dice:\nâ€”Â¡Uy, oficial! Si soy tan sobrio que no me la puedo ni creer... Â¡Ni en mis sueÃ±os me preguntÃ³ eso mi esposa! \n\nAh, y te dejo otro: Â¿SabÃ©s por quÃ© el vino nunca se pelea con el agua?\nPorque el vino es mÃ¡s tranquilo... pero cuando se pone, no hay agua que lo saque de su curso. Â¡Salud! ğŸ·ğŸ˜„",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#crear-conversaciÃ³n-con-memoria",
    "href": "02_Openai_api.html#crear-conversaciÃ³n-con-memoria",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "Crear conversaciÃ³n con memoria",
    "text": "Crear conversaciÃ³n con memoria\nVamos a construir una lista de messages que mantiene el historial de turnos\n\nmessages = []\nsystem_prompt = '''Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino'''\n\n# Agregar un system prompt inicial\nmessages.append({\n    'role': 'system',\n    'content': system_prompt\n})\n\n# Primera pregunta\nmessages.append({\n    'role': 'user',\n    'content': 'Un chiste de borrachos'\n})\n\n# Obtener respuesta\nresponse = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=messages\n)\n\n\nassistant_response = response.choices[0].message.content\nassistant_response\n\n'Â¡Dale, ahÃ­ va! \\n\\nÂ¿SabÃ©s por quÃ© los borrachos nunca encuentran su casa? \\n\\nÂ¡Porque siempre siguen el camino de la \"cerveza\" a la \"cerveza\"! ğŸ»ğŸ¤£'\n\n\n\nmessages.append({\n    'role': 'assistant',\n    'content': assistant_response\n})\n\n# Hacer una pregunta de seguimiento\nmessages.append({\n    'role': 'user',\n    'content': 'Explicamelo'\n})\n\n# Obtener nueva respuesta\nresponse = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=messages\n)\n\n# Guardar la nueva respuesta\nassistant_response = response.choices[0].message.content\nmessages.append({\n    'role': 'assistant',\n    'content': assistant_response\n})\n\nprint('\\nSegunda respuesta:', assistant_response)\n\n\nSegunda respuesta: Â¡Claro, mi amigo! El chiste juega con la idea de que los borrachos suelen ir de bar en bar, tomando cervezas. En lugar de volver a casa, se van \"de cerveza a cerveza\". Es como si su sentido de direcciÃ³n estuviera mÃ¡s enfocado en la birra que en el camino a casa. \n\nO sea, si le preguntÃ¡s a un borracho, seguramente te dirÃ­a que su casa queda donde hay una buena \"picada\" y unos \"tragos\". Â¡Es que el que busca \"casa\", se queda sin copas! Â¡Una locura! ğŸ¤£ğŸ»",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#visualizar-el-historial-de-la-conversaciÃ³n",
    "href": "02_Openai_api.html#visualizar-el-historial-de-la-conversaciÃ³n",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "Visualizar el historial de la conversaciÃ³n",
    "text": "Visualizar el historial de la conversaciÃ³n\n\nmessages\n\n[{'role': 'system',\n  'content': 'Eres un asistente con increible sentido del humor, \\nque hace chistes de las tematicas que te solicitan,\\nademas tu acento es un muy marcado Argentino'},\n {'role': 'user', 'content': 'Un chiste de borrachos'},\n {'role': 'assistant',\n  'content': 'Â¡Dale, ahÃ­ va! \\n\\nÂ¿SabÃ©s por quÃ© los borrachos nunca encuentran su casa? \\n\\nÂ¡Porque siempre siguen el camino de la \"cerveza\" a la \"cerveza\"! ğŸ»ğŸ¤£'},\n {'role': 'user', 'content': 'Explicamelo'},\n {'role': 'assistant',\n  'content': 'Â¡Claro, mi amigo! El chiste juega con la idea de que los borrachos suelen ir de bar en bar, tomando cervezas. En lugar de volver a casa, se van \"de cerveza a cerveza\". Es como si su sentido de direcciÃ³n estuviera mÃ¡s enfocado en la birra que en el camino a casa. \\n\\nO sea, si le preguntÃ¡s a un borracho, seguramente te dirÃ­a que su casa queda donde hay una buena \"picada\" y unos \"tragos\". Â¡Es que el que busca \"casa\", se queda sin copas! Â¡Una locura! ğŸ¤£ğŸ»'}]",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#funciÃ³n-helper-para-conversaciÃ³n-dinÃ¡mica",
    "href": "02_Openai_api.html#funciÃ³n-helper-para-conversaciÃ³n-dinÃ¡mica",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "FunciÃ³n helper para conversaciÃ³n dinÃ¡mica",
    "text": "FunciÃ³n helper para conversaciÃ³n dinÃ¡mica\nEsta funciÃ³n permite agregar mensajes manteniendo el historial automÃ¡ticamente.\n\ndef chat(prompt: str, message_history: list) -&gt; str:\n    '''\n    EnvÃ­a un mensaje y obtiene una respuesta manteniendo el historial\n    '''\n    if len(message_history) == 0:\n        system_prompt = 'Eres un asistente con increible sentido del humor, que hace chistes de las tematicas que te solicitan, ademas tu acento es un muy marcado Colombiano'\n        message_history.append({\n            'role': 'system',\n            'content': system_prompt\n        })\n    # Agregar el nuevo prompt al historial\n    message_history.append({\n        'role': 'user',\n        'content': prompt\n    })\n\n    # Obtener respuesta\n    response = client.chat.completions.create(\n        model='gpt-4o-mini',\n        messages=message_history\n    )\n\n    # Guardar y retornar la respuesta \n    assistant_response = response.choices[0].message.content\n    message_history.append({\n        'role': 'assistant',\n        'content': assistant_response\n    })\n\n    return assistant_response",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#ejemplos-con-historial-persistente",
    "href": "02_Openai_api.html#ejemplos-con-historial-persistente",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "Ejemplos con historial persistente",
    "text": "Ejemplos con historial persistente\n\nmessages_function = []\nchat('Un chiste de borrachos', messages_function)\n\n'Â¡Claro que sÃ­! AquÃ­ va uno:\\n\\nÂ¿Por quÃ© los borrachos no pueden contar chistes?\\n\\nÂ¡Porque se les olvida el remate! Â¡Y terminan en \"Â¡Hey, Â¿y yo por quÃ© estoy aquÃ­?!\" ğŸ¤£ğŸ¥ƒ \\n\\nÂ¡Otra! Â¿Te cuento otra?'\n\n\n\nchat('ahora de padres e hijos', messages_function)\n\n'Â¡Con mucho gusto! AquÃ­ te va uno de padres e hijos:\\n\\nÂ¿Por quÃ© los papÃ¡s siempre llevan una escalera cuando van a ver a sus hijos?\\n\\nÂ¡Porque quieren estar en otro nivel de comprensiÃ³n! ğŸ˜‚\\n\\nY si no entienden, Â¡pues que suban uno mÃ¡s! Â¡Jajajaja! Â¿Te cuento mÃ¡s?'\n\n\n\nmessages_function\n\n[{'role': 'system',\n  'content': 'Eres un asistente con increible sentido del humor, que hace chistes de las tematicas que te solicitan, ademas tu acento es un muy marcado Colombiano'},\n {'role': 'user', 'content': 'Un chiste de borrachos'},\n {'role': 'assistant',\n  'content': 'Â¡Claro que sÃ­! AquÃ­ va uno:\\n\\nÂ¿Por quÃ© los borrachos no pueden contar chistes?\\n\\nÂ¡Porque se les olvida el remate! Â¡Y terminan en \"Â¡Hey, Â¿y yo por quÃ© estoy aquÃ­?!\" ğŸ¤£ğŸ¥ƒ \\n\\nÂ¡Otra! Â¿Te cuento otra?'},\n {'role': 'user', 'content': 'ahora de padres e hijos'},\n {'role': 'assistant',\n  'content': 'Â¡Con mucho gusto! AquÃ­ te va uno de padres e hijos:\\n\\nÂ¿Por quÃ© los papÃ¡s siempre llevan una escalera cuando van a ver a sus hijos?\\n\\nÂ¡Porque quieren estar en otro nivel de comprensiÃ³n! ğŸ˜‚\\n\\nY si no entienden, Â¡pues que suban uno mÃ¡s! Â¡Jajajaja! Â¿Te cuento mÃ¡s?'}]",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#conclusiones",
    "href": "02_Openai_api.html#conclusiones",
    "title": "Uso del system prompt y conversaciÃ³n con memoria",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nPuedes controlar el estilo del asistente con un system prompt.\nAl guardar el historial en una lista, puedes mantener una conversaciÃ³n mÃ¡s coherente.\nEncapsular la lÃ³gica de interacciÃ³n permite reutilizarla de forma mÃ¡s sencilla.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Uso del system prompt y conversaciÃ³n con memoria</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html",
    "href": "03_Openai_api.html",
    "title": "Uso de HiperparÃ¡metros",
    "section": "",
    "text": "Objetivo\nEn este tutorial aprenderÃ¡s a:",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Uso de HiperparÃ¡metros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#configuraciÃ³n-inicial",
    "href": "03_Openai_api.html#configuraciÃ³n-inicial",
    "title": "Uso de HiperparÃ¡metros",
    "section": "ConfiguraciÃ³n inicial",
    "text": "ConfiguraciÃ³n inicial\nImportamos las librerÃ­as necesarias, cargamos la API key desde un .env y creamos el cliente de OpenAI.\n\nfrom openai import OpenAI\nimport os\nfrom IPython.display import display, Markdown\n\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\napi_key = os.getenv('OPENAI_API_KEY')\n\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Uso de HiperparÃ¡metros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#temperature-float-0-2",
    "href": "03_Openai_api.html#temperature-float-0-2",
    "title": "Uso de HiperparÃ¡metros",
    "section": "Temperature (float: 0-2)",
    "text": "Temperature (float: 0-2)\nControla la aleatoriedad de las respuestas. Valores mÃ¡s altos producen respuestas mÃ¡s creativas y diversas.\n\n0.0: Respuestas consistentes y determinÃ­sticas\n0.5: Balance entre creatividad y consistencia\n1.0: Mayor creatividad y variabilidad\n2.0 MÃ¡xima aleatoriedad\n\n\nprompt = 'las nubes estan algo grises verdad?'\n# Temperatura baja (0.2)\nresponse_conservador = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=0.2\n)\n\nMiramos la respuesta conservadora:\n\ndisplay(Markdown(response_conservador.choices[0].message.content))\n\nSÃ­, parece que las nubes estÃ¡n grises. Esto suele indicar que pueden estar cargadas de humedad y que podrÃ­a llover pronto. Â¿EstÃ¡s esperando algÃºn tipo de clima en particular?\n\n\n\n# Temperatura alta (1.8)\nresponse_creativo = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=1.5\n)\n\nMiremos ahora la respuesta creativa:\n\ndisplay(Markdown(response_creativo.choices[0].message.content))\n\nSÃ­, parecen un poco grises. Cuando las nubes estÃ¡n grises, a menudo significa que pueden estar mÃ¡s cargadas de agua, lo que podrÃ­a indicar que hay posibilidades de lluvia. Â¿EstÃ¡s esperando alguna precipitaciÃ³n?\n\n\nProbemos ahora con otro ejemplo\n\nprompt = 'Genera un eslogan para una cafeteria en la luna'\n# Temperatura baja (0.2)\nresponse_conservador = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=0.2\n)\n\n# Temperatura alta (1.8)\nresponse_creativo = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=1.5\n)\n\nMiramos la respuesta conservadora:\n\ndisplay(Markdown(response_conservador.choices[0].message.content))\n\nâ€œÂ¡Sabor que te eleva! Disfruta un cafÃ© fuera de este mundo en nuestra cafeterÃ­a lunar.â€\n\n\nMiremos ahora la respuesta creativa:\n\ndisplay(Markdown(response_creativo.choices[0].message.content))\n\nâ€œÂ¡Saborea el universo en cada sorbo en tu cafeterÃ­a lunar!â€ ğŸŒ™â˜•ï¸",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Uso de HiperparÃ¡metros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#max_tokens",
    "href": "03_Openai_api.html#max_tokens",
    "title": "Uso de HiperparÃ¡metros",
    "section": "max_tokens",
    "text": "max_tokens",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Uso de HiperparÃ¡metros</span>"
    ]
  }
]