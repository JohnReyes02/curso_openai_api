[
  {
    "objectID": "01_Openai_api.html",
    "href": "01_Openai_api.html",
    "title": "Uso básico de la API de OpenAI",
    "section": "",
    "text": "Configuración Inicial\nEste tutorial muestra cómo usar la API de OpenAI con la biblioteca oficial\nImportamos las librerías necesarias y cargamos las variables de entorno.\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()  # Carga el archivo de las variables de entorno\n\napi_key = os.getenv('OPENAI_API_KEY')\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#solicitud-a-la-api",
    "href": "01_Openai_api.html#solicitud-a-la-api",
    "title": "Uso básico de la API de OpenAI",
    "section": "Solicitud a la API",
    "text": "Solicitud a la API\nUsamos el modelo gpt-4o-mini para enviar un mensaje y obtener una respuesta.\n\ncompletion = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[\n        {\n            'role': 'user',\n            'content': '¡Hola! ¿Me ayudas a aprender sobre la API de OpenAI'\n        }\n    ]\n)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#ver-la-respuesta",
    "href": "01_Openai_api.html#ver-la-respuesta",
    "title": "Uso básico de la API de OpenAI",
    "section": "Ver la respuesta",
    "text": "Ver la respuesta\nExtraemos el contenido de la respuesta del asistente.\n\ncompletion.choices[0].message\n\nChatCompletionMessage(content='¡Hola! Claro que sí, estaré encantado de ayudarte a aprender sobre la API de OpenAI. \\n\\n### ¿Qué es la API de OpenAI?\\nLa API de OpenAI proporciona acceso a modelos de inteligencia artificial avanzados, como GPT-3 y otros, que pueden ser utilizados para tareas como generación de texto, traducción, resumen, entre otros.\\n\\n### Cómo empezar\\n\\n1. **Registro y Obtención de Claves**: Primero, necesitas registrarte en el sitio de OpenAI y obtener una clave de API. Esta clave te permitirá autenticarte y hacer llamadas a la API.\\n\\n2. **Documentación**: Es fundamental familiarizarse con la [documentación oficial de OpenAI](https://platform.openai.com/docs/). Allí encontrarás ejemplos, guías y referencias sobre cómo usar la API.\\n\\n3. **Integración**: Puedes hacer llamadas a la API utilizando varios lenguajes de programación. Algunos de los más comunes son Python, JavaScript, y otros. Aquí te muestro un ejemplo simple usando Python:\\n\\n    ```python\\n    import openai\\n\\n    openai.api_key = \\'tu_clave_api\\'\\n\\n    response = openai.ChatCompletion.create(\\n        model=\"gpt-3.5-turbo\",\\n        messages=[\\n            {\"role\": \"user\", \"content\": \"Hola, ¿qué puedes hacer?\"}\\n        ]\\n    )\\n\\n    print(response[\\'choices\\'][0][\\'message\\'][\\'content\\'])\\n    ```\\n\\n### Principales funcionalidades\\n\\n1. **Generación de texto**: Puedes generar texto a partir de un prompt inicial.\\n2. **Chat**: Puedes tener conversaciones interactivas con el modelo como si fuera un chatbot.\\n3. **Asistente de programación**: Puedes pedir ayuda con código, soluciones a problemas y más.\\n4. **Análisis de texto**: Puedes pedir resúmenes, explicaciones o análisis sobre textos.\\n\\n### Mejores Prácticas\\n\\n- **Uso de prompts claros**: Asegúrate de que los prompts sean específicos y claros para obtener mejores resultados.\\n- **Manejo de tokens**: La API tiene límites de tokens por solicitud, así que es importante mantener un control sobre la longitud de los textos que envías y recibes.\\n- **Gestión de errores**: Implementa un manejo adecuado de errores para responder a posibles fallos en las solicitudes.\\n\\n### Caso de uso\\n\\nLa API de OpenAI tiene múltiples aplicaciones, como chatbots, asistentes virtuales, generación de contenido para blogs, y mucho más.\\n\\nSi tienes alguna pregunta específica o un área en la que te gustaría profundizar más, ¡dímelo!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#mostrar-la-respuesta-en-formato-markdown",
    "href": "01_Openai_api.html#mostrar-la-respuesta-en-formato-markdown",
    "title": "Uso básico de la API de OpenAI",
    "section": "Mostrar la respuesta en formato Markdown",
    "text": "Mostrar la respuesta en formato Markdown\nUtilizamos IPyhton para mostrar el contenido como texto formateado.\n\nfrom IPython.display import display, Markdown\ndisplay(Markdown(completion.choices[0].message.content))\n\n¡Hola! Claro que sí, estaré encantado de ayudarte a aprender sobre la API de OpenAI.\n\n¿Qué es la API de OpenAI?\nLa API de OpenAI proporciona acceso a modelos de inteligencia artificial avanzados, como GPT-3 y otros, que pueden ser utilizados para tareas como generación de texto, traducción, resumen, entre otros.\n\n\nCómo empezar\n\nRegistro y Obtención de Claves: Primero, necesitas registrarte en el sitio de OpenAI y obtener una clave de API. Esta clave te permitirá autenticarte y hacer llamadas a la API.\nDocumentación: Es fundamental familiarizarse con la documentación oficial de OpenAI. Allí encontrarás ejemplos, guías y referencias sobre cómo usar la API.\nIntegración: Puedes hacer llamadas a la API utilizando varios lenguajes de programación. Algunos de los más comunes son Python, JavaScript, y otros. Aquí te muestro un ejemplo simple usando Python:\nimport openai\n\nopenai.api_key = 'tu_clave_api'\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hola, ¿qué puedes hacer?\"}\n    ]\n)\n\nprint(response['choices'][0]['message']['content'])\n\n\n\nPrincipales funcionalidades\n\nGeneración de texto: Puedes generar texto a partir de un prompt inicial.\nChat: Puedes tener conversaciones interactivas con el modelo como si fuera un chatbot.\nAsistente de programación: Puedes pedir ayuda con código, soluciones a problemas y más.\nAnálisis de texto: Puedes pedir resúmenes, explicaciones o análisis sobre textos.\n\n\n\nMejores Prácticas\n\nUso de prompts claros: Asegúrate de que los prompts sean específicos y claros para obtener mejores resultados.\nManejo de tokens: La API tiene límites de tokens por solicitud, así que es importante mantener un control sobre la longitud de los textos que envías y recibes.\nGestión de errores: Implementa un manejo adecuado de errores para responder a posibles fallos en las solicitudes.\n\n\n\nCaso de uso\nLa API de OpenAI tiene múltiples aplicaciones, como chatbots, asistentes virtuales, generación de contenido para blogs, y mucho más.\nSi tienes alguna pregunta específica o un área en la que te gustaría profundizar más, ¡dímelo!",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#ver-el-rol-del-mensaje",
    "href": "01_Openai_api.html#ver-el-rol-del-mensaje",
    "title": "Uso básico de la API de OpenAI",
    "section": "Ver el rol del mensaje",
    "text": "Ver el rol del mensaje\n\nprint(completion.choices[0].message.role)\n\nassistant",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#conclusiones",
    "href": "01_Openai_api.html#conclusiones",
    "title": "Uso básico de la API de OpenAI",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nEste ejemplo muestra cómo configurar y hacer un request básico a la API.\nPuedes cambiar el modelo (gpt-4o-mini, gpt-3.5-turbo, etc.) según tus necesidades.\nEl uso de Markdown en la salida más legible la respuesta.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html",
    "href": "02_Openai_api.html",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "",
    "text": "Objetivo\nEn este tutorial aprenderás a:",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#objetivo",
    "href": "02_Openai_api.html#objetivo",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "",
    "text": "Usar un system prompt para dar contexto al asistente.\nRealizar llamadas con humor y estilo específico.\nConstruir una conversación con memoria de mensajes anteriores.\nEncapsular la lógica de interacción en una función reutilizable.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#configuración-inicial",
    "href": "02_Openai_api.html#configuración-inicial",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Configuración Inicial",
    "text": "Configuración Inicial\nImportamos librerías necesarias, cargamos la API key desde un .env y creamos un cliente de OpenAI.\n\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\napi_key = os.getenv('OPENAI_API_KEY')\n\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#función-par-enviar-mensajes-con-system_promt",
    "href": "02_Openai_api.html#función-par-enviar-mensajes-con-system_promt",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Función par enviar mensajes con system_promt",
    "text": "Función par enviar mensajes con system_promt\nEsta función permite enviar un prompt con rol system que define el estilo del asistente.\n\ndef chat_with_system(system_prompt: str, user_prompt: str) -&gt; str:\n    '''Realiza una llamada con system prompt'''\n    try:\n        response = client.chat.completions.create(\n            model='gpt-4o',\n            messages=[\n                {'role': 'system', 'content': system_prompt},\n                {'role': 'user', 'content': user_prompt}\n            ]\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        return f'Error: {str(e)}'",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#ejemplo-de-uso-con-humor-y-acento-argentino",
    "href": "02_Openai_api.html#ejemplo-de-uso-con-humor-y-acento-argentino",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Ejemplo de uso con humor y acento argentino",
    "text": "Ejemplo de uso con humor y acento argentino\n\nsystem_prompt = '''Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino'''\nuser_prompt = 'algo de borrachos'\nrespuesta = chat_with_system(system_prompt, user_prompt)\n\nprint(f'\\nSystem Prompt: {system_prompt}')\nprint(f'\\nUser Prompt: {user_prompt}')\nprint(f'\\nRespuesta: {respuesta}')\n\n\nSystem Prompt: Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino\n\nUser Prompt: algo de borrachos\n\nRespuesta: ¡Ah, los borrachos! Son como los héroes anónimos de las fiestas, ¿no? Siempre dispuestos a dar la nota, aunque sea por accidente. \n\nMirá, te cuento uno: Un borracho entra a un bar y le dice al barman: \"¿Me da una cerveza, por favor?\" El barman le responde: \"Disculpe, señor, pero hemos cerrado.\" A lo que el borracho le contesta: \"¿Y qué? ¿No me la puedo llevar puesta?\" 😆\n\nO este otro: Un borracho está caminando en zigzag por la calle, hasta que un policía lo detiene y le dice: \"Eh, amigo, ¿dónde va así?\" El borracho responde: \"¡Estoy ensayando una línea recta para el examen de manejo!\" 🤪\n\nEsos personajes siempre hacen que las anécdotas de las fiestas se mantengan vivas, ¿no te parece? ¡Salud! 🍻",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#crear-conversación-con-memoria",
    "href": "02_Openai_api.html#crear-conversación-con-memoria",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Crear conversación con memoria",
    "text": "Crear conversación con memoria\nVamos a construir una lista de messages que mantiene el historial de turnos\n\nmessages = []\nsystem_prompt = '''Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino'''\n\n# Agregar un system prompt inicial\nmessages.append({\n    'role': 'system',\n    'content': system_prompt\n})\n\n# Primera pregunta\nmessages.append({\n    'role': 'user',\n    'content': 'Un chiste de borrachos'\n})\n\n# Obtener respuesta\nresponse = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=messages\n)\n\n\nassistant_response = response.choices[0].message.content\nassistant_response\n\n'¡Claro, che! Ahí va uno:\\n\\n¿Cómo se llama el borracho que sabe cantar? \\n\\n¡Paco! Porque siempre va al bar y pide \"un trago y otro, ¡y otro más!\"  🍻🎤 \\n\\n¡Qué sería de la vida sin un poco de humor y unos tragos!'\n\n\n\nmessages.append({\n    'role': 'assistant',\n    'content': assistant_response\n})\n\n# Hacer una pregunta de seguimiento\nmessages.append({\n    'role': 'user',\n    'content': 'Explicamelo'\n})\n\n# Obtener nueva respuesta\nresponse = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=messages\n)\n\n# Guardar la nueva respuesta\nassistant_response = response.choices[0].message.content\nmessages.append({\n    'role': 'assistant',\n    'content': assistant_response\n})\n\nprint('\\nSegunda respuesta:', assistant_response)\n\n\nSegunda respuesta: ¡Dale, te lo explico! \n\nEl chiste juega con la idea de un borracho que canta. El nombre \"Paco\" en este contexto es un simple juego de palabras. Se sugiere que siempre está \"pidiendo trago\" porque se lo escucha gritar \"¡un trago, y otro, y otro más!\" como si fuera una melodía. Es como si fuera el protagonista de una canción, aunque en realidad, está todo el tiempo en el bar, pedido otro trago más. \n\n¡La mezcla de la música y el alcohol da para unos buenos momentos de risa, no? ¡Es un clásico! 🍻😄",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#visualizar-el-historial-de-la-conversación",
    "href": "02_Openai_api.html#visualizar-el-historial-de-la-conversación",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Visualizar el historial de la conversación",
    "text": "Visualizar el historial de la conversación\n\nmessages\n\n[{'role': 'system',\n  'content': 'Eres un asistente con increible sentido del humor, \\nque hace chistes de las tematicas que te solicitan,\\nademas tu acento es un muy marcado Argentino'},\n {'role': 'user', 'content': 'Un chiste de borrachos'},\n {'role': 'assistant',\n  'content': '¡Claro, che! Ahí va uno:\\n\\n¿Cómo se llama el borracho que sabe cantar? \\n\\n¡Paco! Porque siempre va al bar y pide \"un trago y otro, ¡y otro más!\"  🍻🎤 \\n\\n¡Qué sería de la vida sin un poco de humor y unos tragos!'},\n {'role': 'user', 'content': 'Explicamelo'},\n {'role': 'assistant',\n  'content': '¡Dale, te lo explico! \\n\\nEl chiste juega con la idea de un borracho que canta. El nombre \"Paco\" en este contexto es un simple juego de palabras. Se sugiere que siempre está \"pidiendo trago\" porque se lo escucha gritar \"¡un trago, y otro, y otro más!\" como si fuera una melodía. Es como si fuera el protagonista de una canción, aunque en realidad, está todo el tiempo en el bar, pedido otro trago más. \\n\\n¡La mezcla de la música y el alcohol da para unos buenos momentos de risa, no? ¡Es un clásico! 🍻😄'}]",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#función-helper-para-conversación-dinámica",
    "href": "02_Openai_api.html#función-helper-para-conversación-dinámica",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Función helper para conversación dinámica",
    "text": "Función helper para conversación dinámica\nEsta función permite agregar mensajes manteniendo el historial automáticamente.\n\ndef chat(prompt: str, message_history: list) -&gt; str:\n    '''\n    Envía un mensaje y obtiene una respuesta manteniendo el historial\n    '''\n    if len(message_history) == 0:\n        system_prompt = 'Eres un asistente con increible sentido del humor, que hace chistes de las tematicas que te solicitan, ademas tu acento es un muy marcado Colombiano'\n        message_history.append({\n            'role': 'system',\n            'content': system_prompt\n        })\n    # Agregar el nuevo prompt al historial\n    message_history.append({\n        'role': 'user',\n        'content': prompt\n    })\n\n    # Obtener respuesta\n    response = client.chat.completions.create(\n        model='gpt-4o-mini',\n        messages=message_history\n    )\n\n    # Guardar y retornar la respuesta \n    assistant_response = response.choices[0].message.content\n    message_history.append({\n        'role': 'assistant',\n        'content': assistant_response\n    })\n\n    return assistant_response",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#ejemplos-con-historial-persistente",
    "href": "02_Openai_api.html#ejemplos-con-historial-persistente",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Ejemplos con historial persistente",
    "text": "Ejemplos con historial persistente\n\nmessages_function = []\nchat('Un chiste de borrachos', messages_function)\n\n'¡Claro que sí, parcerito! Aquí va uno:\\n\\n¿Por qué los borrachos nunca cuentan secretos en el bar?\\n\\nPorque en el fondo, ¡todos son unos \"escuchadores\"! 🥴😂\\n\\n¿Entendiste? Porque siempre están \"escuchando\" a todo volumen. ¡Más bien me voy a la \"escuchada\"! 🍻'\n\n\n\nchat('ahora de padres e hijos', messages_function)\n\n'¡Dale! Aquí te va uno de padres e hijos:\\n\\n¿Por qué los padres siempre llevan a sus hijos al parque?\\n\\n¡Porque cada vez que dicen \"¡Voy a estar en forma!\" terminan encontrando una \"forma\" de no hacer nada y ponerle la culpa a los muchachos! 😂🌳\\n\\n¡Ay, la vida! Un día están en el parque y al otro preguntándote por qué te quedaste en la casa. ¡Yo no entiendo nada! 🤷\\u200d♂️'\n\n\n\nmessages_function\n\n[{'role': 'system',\n  'content': 'Eres un asistente con increible sentido del humor, que hace chistes de las tematicas que te solicitan, ademas tu acento es un muy marcado Colombiano'},\n {'role': 'user', 'content': 'Un chiste de borrachos'},\n {'role': 'assistant',\n  'content': '¡Claro que sí, parcerito! Aquí va uno:\\n\\n¿Por qué los borrachos nunca cuentan secretos en el bar?\\n\\nPorque en el fondo, ¡todos son unos \"escuchadores\"! 🥴😂\\n\\n¿Entendiste? Porque siempre están \"escuchando\" a todo volumen. ¡Más bien me voy a la \"escuchada\"! 🍻'},\n {'role': 'user', 'content': 'ahora de padres e hijos'},\n {'role': 'assistant',\n  'content': '¡Dale! Aquí te va uno de padres e hijos:\\n\\n¿Por qué los padres siempre llevan a sus hijos al parque?\\n\\n¡Porque cada vez que dicen \"¡Voy a estar en forma!\" terminan encontrando una \"forma\" de no hacer nada y ponerle la culpa a los muchachos! 😂🌳\\n\\n¡Ay, la vida! Un día están en el parque y al otro preguntándote por qué te quedaste en la casa. ¡Yo no entiendo nada! 🤷\\u200d♂️'}]",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#conclusiones",
    "href": "02_Openai_api.html#conclusiones",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nPuedes controlar el estilo del asistente con un system prompt.\nAl guardar el historial en una lista, puedes mantener una conversación más coherente.\nEncapsular la lógica de interacción permite reutilizarla de forma más sencilla.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html",
    "href": "03_Openai_api.html",
    "title": "Uso de Hiperparámetros",
    "section": "",
    "text": "Objetivo\nEn este tutorial aprenderás a:",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#configuración-inicial",
    "href": "03_Openai_api.html#configuración-inicial",
    "title": "Uso de Hiperparámetros",
    "section": "Configuración inicial",
    "text": "Configuración inicial\nImportamos las librerías necesarias, cargamos la API key desde un .env y creamos el cliente de OpenAI.\n\nfrom openai import OpenAI\nimport os\nfrom IPython.display import display, Markdown\n\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\napi_key = os.getenv('OPENAI_API_KEY')\n\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#temperature-float-0-2",
    "href": "03_Openai_api.html#temperature-float-0-2",
    "title": "Uso de Hiperparámetros",
    "section": "Temperature (float: 0-2)",
    "text": "Temperature (float: 0-2)\nControla la aleatoriedad de las respuestas. Valores más altos producen respuestas más creativas y diversas.\n\n0.0: Respuestas consistentes y determinísticas\n0.5: Balance entre creatividad y consistencia\n1.0: Mayor creatividad y variabilidad\n2.0 Máxima aleatoriedad\n\n\nprompt = 'las nubes estan algo grises verdad?'\n# Temperatura baja (0.2)\nresponse_conservador = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=0.2\n)\n\nMiramos la respuesta conservadora:\n\ndisplay(Markdown(response_conservador.choices[0].message.content))\n\nSí, parece que las nubes están grises. Esto suele indicar que pueden estar cargadas de humedad y que podría llover pronto. ¿Estás esperando algún tipo de clima en particular?\n\n\n\n# Temperatura alta (1.8)\nresponse_creativo = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=1.5\n)\n\nMiremos ahora la respuesta creativa:\n\ndisplay(Markdown(response_creativo.choices[0].message.content))\n\nSí, parecen un poco grises. Cuando las nubes están grises, a menudo significa que pueden estar más cargadas de agua, lo que podría indicar que hay posibilidades de lluvia. ¿Estás esperando alguna precipitación?\n\n\nProbemos ahora con otro ejemplo\n\nprompt = 'Genera un eslogan para una cafeteria en la luna'\n# Temperatura baja (0.2)\nresponse_conservador = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=0.2\n)\n\n# Temperatura alta (1.8)\nresponse_creativo = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=1.5\n)\n\nMiramos la respuesta conservadora:\n\ndisplay(Markdown(response_conservador.choices[0].message.content))\n\n“¡Sabor que te eleva! Disfruta un café fuera de este mundo en nuestra cafetería lunar.”\n\n\nMiremos ahora la respuesta creativa:\n\ndisplay(Markdown(response_creativo.choices[0].message.content))\n\n“¡Saborea el universo en cada sorbo en tu cafetería lunar!” 🌙☕️",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#max_tokens",
    "href": "03_Openai_api.html#max_tokens",
    "title": "Uso de Hiperparámetros",
    "section": "max_tokens",
    "text": "max_tokens",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Domina el API de OpenAI - De Principiante a Experto",
    "section": "",
    "text": "Bienvenido\nEste libro recopila una serie de tutoriales para aprender a usar la API de OpenAI paso a paso.\n\nEstá escrito en Python\nPuedes ver los resultados directamente\nEs fácil de exportar a HTML y PDF",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Domina el API de OpenAI - De Principiante a Experto</span>"
    ]
  }
]