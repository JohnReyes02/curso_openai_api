[
  {
    "objectID": "01_Openai_api.html",
    "href": "01_Openai_api.html",
    "title": "Uso básico de la API de OpenAI",
    "section": "",
    "text": "Configuración Inicial\nEste tutorial muestra cómo usar la API de OpenAI con la biblioteca oficial\nImportamos las librerías necesarias y cargamos las variables de entorno.\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()  # Carga el archivo de las variables de entorno\n\napi_key = os.getenv('OPENAI_API_KEY')\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#solicitud-a-la-api",
    "href": "01_Openai_api.html#solicitud-a-la-api",
    "title": "Uso básico de la API de OpenAI",
    "section": "Solicitud a la API",
    "text": "Solicitud a la API\nUsamos el modelo gpt-4o-mini para enviar un mensaje y obtener una respuesta.\n\ncompletion = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[\n        {\n            'role': 'user',\n            'content': '¡Hola! ¿Me ayudas a aprender sobre la API de OpenAI'\n        }\n    ]\n)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#ver-la-respuesta",
    "href": "01_Openai_api.html#ver-la-respuesta",
    "title": "Uso básico de la API de OpenAI",
    "section": "Ver la respuesta",
    "text": "Ver la respuesta\nExtraemos el contenido de la respuesta del asistente.\n\ncompletion.choices[0].message\n\nChatCompletionMessage(content='¡Hola! Claro que sí, estaré encantado de ayudarte a aprender sobre la API de OpenAI. La API de OpenAI proporciona acceso a los modelos de lenguaje de OpenAI, como GPT-3 y GPT-4, entre otros. Aquí tienes un resumen para empezar:\\n\\n### 1. **¿Qué es la API de OpenAI?**\\n   - Es una interfaz que permite a los desarrolladores interactuar con los modelos de IA de OpenAI.\\n   - Se puede usar para tareas como generación de texto, traducción, respuesta a preguntas, y más.\\n\\n### 2. **¿Cómo funciona?**\\n   - Envías una solicitud HTTP que incluye tu mensaje o prompt.\\n   - La API procesa el input y devuelve una respuesta generada por el modelo.\\n\\n### 3. **Inicio Rápido:**\\n   - **Registro:** Necesitas registrarte en el sitio de OpenAI y obtener una clave de API.\\n   - **Librería:** Puedes usar bibliotecas como `requests` (en Python) para hacer llamadas a la API.\\n\\n### 4. **Ejemplo de Código (Python):**\\n```python\\nimport openai\\n\\nopenai.api_key = \\'tu_clave_de_api\\'\\n\\nrespuesta = openai.ChatCompletion.create(\\n    model=\"gpt-3.5-turbo\",  # O cualquier modelo que estés utilizando\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"Hola, ¿puedes ayudarme con un problema?\"}\\n    ]\\n)\\n\\nprint(respuesta[\\'choices\\'][0][\\'message\\'][\\'content\\'])\\n```\\n\\n### 5. **Parámetros Clave:**\\n   - **model:** Especifica el modelo a utilizar (ej. \"gpt-3.5-turbo\").\\n   - **messages:** Una lista de mensajes que simulan una conversación, donde cada mensaje tiene un rol (\\'user\\', \\'assistant\\', etc.).\\n   - **max_tokens:** Controla la longitud máxima de la respuesta.\\n   - **temperature:** Controla la creatividad en la respuesta (valores entre 0 y 1).\\n\\n### 6. **Costos:**\\n   - La API tiene un costo basado en el número de tokens procesados. Asegúrate de consultar la página de precios para obtener detalles.\\n\\n### 7. **Consideraciones:**\\n   - Siempre revisa las políticas de uso de OpenAI para asegurarte de que estás utilizando la API de manera ética.\\n   - Trata de optimizar tus prompts para obtener mejores respuestas.\\n\\nSi tienes alguna pregunta específica o un área en la que te gustaría profundizar más, ¡házmelo saber!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#mostrar-la-respuesta-en-formato-markdown",
    "href": "01_Openai_api.html#mostrar-la-respuesta-en-formato-markdown",
    "title": "Uso básico de la API de OpenAI",
    "section": "Mostrar la respuesta en formato Markdown",
    "text": "Mostrar la respuesta en formato Markdown\nUtilizamos IPyhton para mostrar el contenido como texto formateado.\n\nfrom IPython.display import display, Markdown\ndisplay(Markdown(completion.choices[0].message.content))\n\n¡Hola! Claro que sí, estaré encantado de ayudarte a aprender sobre la API de OpenAI. La API de OpenAI proporciona acceso a los modelos de lenguaje de OpenAI, como GPT-3 y GPT-4, entre otros. Aquí tienes un resumen para empezar:\n\n1. ¿Qué es la API de OpenAI?\n\nEs una interfaz que permite a los desarrolladores interactuar con los modelos de IA de OpenAI.\nSe puede usar para tareas como generación de texto, traducción, respuesta a preguntas, y más.\n\n\n\n2. ¿Cómo funciona?\n\nEnvías una solicitud HTTP que incluye tu mensaje o prompt.\nLa API procesa el input y devuelve una respuesta generada por el modelo.\n\n\n\n3. Inicio Rápido:\n\nRegistro: Necesitas registrarte en el sitio de OpenAI y obtener una clave de API.\nLibrería: Puedes usar bibliotecas como requests (en Python) para hacer llamadas a la API.\n\n\n\n4. Ejemplo de Código (Python):\nimport openai\n\nopenai.api_key = 'tu_clave_de_api'\n\nrespuesta = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",  # O cualquier modelo que estés utilizando\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hola, ¿puedes ayudarme con un problema?\"}\n    ]\n)\n\nprint(respuesta['choices'][0]['message']['content'])\n\n\n5. Parámetros Clave:\n\nmodel: Especifica el modelo a utilizar (ej. “gpt-3.5-turbo”).\nmessages: Una lista de mensajes que simulan una conversación, donde cada mensaje tiene un rol (‘user’, ‘assistant’, etc.).\nmax_tokens: Controla la longitud máxima de la respuesta.\ntemperature: Controla la creatividad en la respuesta (valores entre 0 y 1).\n\n\n\n6. Costos:\n\nLa API tiene un costo basado en el número de tokens procesados. Asegúrate de consultar la página de precios para obtener detalles.\n\n\n\n7. Consideraciones:\n\nSiempre revisa las políticas de uso de OpenAI para asegurarte de que estás utilizando la API de manera ética.\nTrata de optimizar tus prompts para obtener mejores respuestas.\n\nSi tienes alguna pregunta específica o un área en la que te gustaría profundizar más, ¡házmelo saber!",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#ver-el-rol-del-mensaje",
    "href": "01_Openai_api.html#ver-el-rol-del-mensaje",
    "title": "Uso básico de la API de OpenAI",
    "section": "Ver el rol del mensaje",
    "text": "Ver el rol del mensaje\n\nprint(completion.choices[0].message.role)\n\nassistant",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "01_Openai_api.html#conclusiones",
    "href": "01_Openai_api.html#conclusiones",
    "title": "Uso básico de la API de OpenAI",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nEste ejemplo muestra cómo configurar y hacer un request básico a la API.\nPuedes cambiar el modelo (gpt-4o-mini, gpt-3.5-turbo, etc.) según tus necesidades.\nEl uso de Markdown en la salida más legible la respuesta.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Uso básico de la API de OpenAI</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html",
    "href": "02_Openai_api.html",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "",
    "text": "Objetivo\nEn este tutorial aprenderás a:",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#objetivo",
    "href": "02_Openai_api.html#objetivo",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "",
    "text": "Usar un system prompt para dar contexto al asistente.\nRealizar llamadas con humor y estilo específico.\nConstruir una conversación con memoria de mensajes anteriores.\nEncapsular la lógica de interacción en una función reutilizable.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#configuración-inicial",
    "href": "02_Openai_api.html#configuración-inicial",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Configuración Inicial",
    "text": "Configuración Inicial\nImportamos librerías necesarias, cargamos la API key desde un .env y creamos un cliente de OpenAI.\n\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\napi_key = os.getenv('OPENAI_API_KEY')\n\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#función-par-enviar-mensajes-con-system_promt",
    "href": "02_Openai_api.html#función-par-enviar-mensajes-con-system_promt",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Función par enviar mensajes con system_promt",
    "text": "Función par enviar mensajes con system_promt\nEsta función permite enviar un prompt con rol system que define el estilo del asistente.\n\ndef chat_with_system(system_prompt: str, user_prompt: str) -&gt; str:\n    '''Realiza una llamada con system prompt'''\n    try:\n        response = client.chat.completions.create(\n            model='gpt-4o',\n            messages=[\n                {'role': 'system', 'content': system_prompt},\n                {'role': 'user', 'content': user_prompt}\n            ]\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        return f'Error: {str(e)}'",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#ejemplo-de-uso-con-humor-y-acento-argentino",
    "href": "02_Openai_api.html#ejemplo-de-uso-con-humor-y-acento-argentino",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Ejemplo de uso con humor y acento argentino",
    "text": "Ejemplo de uso con humor y acento argentino\n\nsystem_prompt = '''Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino'''\nuser_prompt = 'algo de borrachos'\nrespuesta = chat_with_system(system_prompt, user_prompt)\n\nprint(f'\\nSystem Prompt: {system_prompt}')\nprint(f'\\nUser Prompt: {user_prompt}')\nprint(f'\\nRespuesta: {respuesta}')\n\n\nSystem Prompt: Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino\n\nUser Prompt: algo de borrachos\n\nRespuesta: ¡Ah, los borrachos! Mirá, te cuento una historia: estaba un tipo completamente borracho en la puerta de un bar, tratando de llegar a su casa después de una noche de copas. Se acerca un policía y le pregunta:\n—Señor, ¿está usted borracho?\nY el tipo le responde:\n—No oficial, estoy sobrio... sobrio como un juez.\nEl policía se ríe y le dice:\n—Bueno señor, entonces dígame quién es usted.\nEl borracho lo mira extrañado y le dice:\n—¡Uy, oficial! Si soy tan sobrio que no me la puedo ni creer... ¡Ni en mis sueños me preguntó eso mi esposa! \n\nAh, y te dejo otro: ¿Sabés por qué el vino nunca se pelea con el agua?\nPorque el vino es más tranquilo... pero cuando se pone, no hay agua que lo saque de su curso. ¡Salud! 🍷😄",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#crear-conversación-con-memoria",
    "href": "02_Openai_api.html#crear-conversación-con-memoria",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Crear conversación con memoria",
    "text": "Crear conversación con memoria\nVamos a construir una lista de messages que mantiene el historial de turnos\n\nmessages = []\nsystem_prompt = '''Eres un asistente con increible sentido del humor, \nque hace chistes de las tematicas que te solicitan,\nademas tu acento es un muy marcado Argentino'''\n\n# Agregar un system prompt inicial\nmessages.append({\n    'role': 'system',\n    'content': system_prompt\n})\n\n# Primera pregunta\nmessages.append({\n    'role': 'user',\n    'content': 'Un chiste de borrachos'\n})\n\n# Obtener respuesta\nresponse = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=messages\n)\n\n\nassistant_response = response.choices[0].message.content\nassistant_response\n\n'¡Dale, ahí va! \\n\\n¿Sabés por qué los borrachos nunca encuentran su casa? \\n\\n¡Porque siempre siguen el camino de la \"cerveza\" a la \"cerveza\"! 🍻🤣'\n\n\n\nmessages.append({\n    'role': 'assistant',\n    'content': assistant_response\n})\n\n# Hacer una pregunta de seguimiento\nmessages.append({\n    'role': 'user',\n    'content': 'Explicamelo'\n})\n\n# Obtener nueva respuesta\nresponse = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=messages\n)\n\n# Guardar la nueva respuesta\nassistant_response = response.choices[0].message.content\nmessages.append({\n    'role': 'assistant',\n    'content': assistant_response\n})\n\nprint('\\nSegunda respuesta:', assistant_response)\n\n\nSegunda respuesta: ¡Claro, mi amigo! El chiste juega con la idea de que los borrachos suelen ir de bar en bar, tomando cervezas. En lugar de volver a casa, se van \"de cerveza a cerveza\". Es como si su sentido de dirección estuviera más enfocado en la birra que en el camino a casa. \n\nO sea, si le preguntás a un borracho, seguramente te diría que su casa queda donde hay una buena \"picada\" y unos \"tragos\". ¡Es que el que busca \"casa\", se queda sin copas! ¡Una locura! 🤣🍻",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#visualizar-el-historial-de-la-conversación",
    "href": "02_Openai_api.html#visualizar-el-historial-de-la-conversación",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Visualizar el historial de la conversación",
    "text": "Visualizar el historial de la conversación\n\nmessages\n\n[{'role': 'system',\n  'content': 'Eres un asistente con increible sentido del humor, \\nque hace chistes de las tematicas que te solicitan,\\nademas tu acento es un muy marcado Argentino'},\n {'role': 'user', 'content': 'Un chiste de borrachos'},\n {'role': 'assistant',\n  'content': '¡Dale, ahí va! \\n\\n¿Sabés por qué los borrachos nunca encuentran su casa? \\n\\n¡Porque siempre siguen el camino de la \"cerveza\" a la \"cerveza\"! 🍻🤣'},\n {'role': 'user', 'content': 'Explicamelo'},\n {'role': 'assistant',\n  'content': '¡Claro, mi amigo! El chiste juega con la idea de que los borrachos suelen ir de bar en bar, tomando cervezas. En lugar de volver a casa, se van \"de cerveza a cerveza\". Es como si su sentido de dirección estuviera más enfocado en la birra que en el camino a casa. \\n\\nO sea, si le preguntás a un borracho, seguramente te diría que su casa queda donde hay una buena \"picada\" y unos \"tragos\". ¡Es que el que busca \"casa\", se queda sin copas! ¡Una locura! 🤣🍻'}]",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#función-helper-para-conversación-dinámica",
    "href": "02_Openai_api.html#función-helper-para-conversación-dinámica",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Función helper para conversación dinámica",
    "text": "Función helper para conversación dinámica\nEsta función permite agregar mensajes manteniendo el historial automáticamente.\n\ndef chat(prompt: str, message_history: list) -&gt; str:\n    '''\n    Envía un mensaje y obtiene una respuesta manteniendo el historial\n    '''\n    if len(message_history) == 0:\n        system_prompt = 'Eres un asistente con increible sentido del humor, que hace chistes de las tematicas que te solicitan, ademas tu acento es un muy marcado Colombiano'\n        message_history.append({\n            'role': 'system',\n            'content': system_prompt\n        })\n    # Agregar el nuevo prompt al historial\n    message_history.append({\n        'role': 'user',\n        'content': prompt\n    })\n\n    # Obtener respuesta\n    response = client.chat.completions.create(\n        model='gpt-4o-mini',\n        messages=message_history\n    )\n\n    # Guardar y retornar la respuesta \n    assistant_response = response.choices[0].message.content\n    message_history.append({\n        'role': 'assistant',\n        'content': assistant_response\n    })\n\n    return assistant_response",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#ejemplos-con-historial-persistente",
    "href": "02_Openai_api.html#ejemplos-con-historial-persistente",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Ejemplos con historial persistente",
    "text": "Ejemplos con historial persistente\n\nmessages_function = []\nchat('Un chiste de borrachos', messages_function)\n\n'¡Claro que sí! Aquí va uno:\\n\\n¿Por qué los borrachos no pueden contar chistes?\\n\\n¡Porque se les olvida el remate! ¡Y terminan en \"¡Hey, ¿y yo por qué estoy aquí?!\" 🤣🥃 \\n\\n¡Otra! ¿Te cuento otra?'\n\n\n\nchat('ahora de padres e hijos', messages_function)\n\n'¡Con mucho gusto! Aquí te va uno de padres e hijos:\\n\\n¿Por qué los papás siempre llevan una escalera cuando van a ver a sus hijos?\\n\\n¡Porque quieren estar en otro nivel de comprensión! 😂\\n\\nY si no entienden, ¡pues que suban uno más! ¡Jajajaja! ¿Te cuento más?'\n\n\n\nmessages_function\n\n[{'role': 'system',\n  'content': 'Eres un asistente con increible sentido del humor, que hace chistes de las tematicas que te solicitan, ademas tu acento es un muy marcado Colombiano'},\n {'role': 'user', 'content': 'Un chiste de borrachos'},\n {'role': 'assistant',\n  'content': '¡Claro que sí! Aquí va uno:\\n\\n¿Por qué los borrachos no pueden contar chistes?\\n\\n¡Porque se les olvida el remate! ¡Y terminan en \"¡Hey, ¿y yo por qué estoy aquí?!\" 🤣🥃 \\n\\n¡Otra! ¿Te cuento otra?'},\n {'role': 'user', 'content': 'ahora de padres e hijos'},\n {'role': 'assistant',\n  'content': '¡Con mucho gusto! Aquí te va uno de padres e hijos:\\n\\n¿Por qué los papás siempre llevan una escalera cuando van a ver a sus hijos?\\n\\n¡Porque quieren estar en otro nivel de comprensión! 😂\\n\\nY si no entienden, ¡pues que suban uno más! ¡Jajajaja! ¿Te cuento más?'}]",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "02_Openai_api.html#conclusiones",
    "href": "02_Openai_api.html#conclusiones",
    "title": "Uso del system prompt y conversación con memoria",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nPuedes controlar el estilo del asistente con un system prompt.\nAl guardar el historial en una lista, puedes mantener una conversación más coherente.\nEncapsular la lógica de interacción permite reutilizarla de forma más sencilla.",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Uso del system prompt y conversación con memoria</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html",
    "href": "03_Openai_api.html",
    "title": "Uso de Hiperparámetros",
    "section": "",
    "text": "Objetivo\nEn este tutorial aprenderás a:",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#configuración-inicial",
    "href": "03_Openai_api.html#configuración-inicial",
    "title": "Uso de Hiperparámetros",
    "section": "Configuración inicial",
    "text": "Configuración inicial\nImportamos las librerías necesarias, cargamos la API key desde un .env y creamos el cliente de OpenAI.\n\nfrom openai import OpenAI\nimport os\nfrom IPython.display import display, Markdown\n\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\napi_key = os.getenv('OPENAI_API_KEY')\n\nclient = OpenAI(api_key=api_key)",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#temperature-float-0-2",
    "href": "03_Openai_api.html#temperature-float-0-2",
    "title": "Uso de Hiperparámetros",
    "section": "Temperature (float: 0-2)",
    "text": "Temperature (float: 0-2)\nControla la aleatoriedad de las respuestas. Valores más altos producen respuestas más creativas y diversas.\n\n0.0: Respuestas consistentes y determinísticas\n0.5: Balance entre creatividad y consistencia\n1.0: Mayor creatividad y variabilidad\n2.0 Máxima aleatoriedad\n\n\nprompt = 'las nubes estan algo grises verdad?'\n# Temperatura baja (0.2)\nresponse_conservador = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=0.2\n)\n\nMiramos la respuesta conservadora:\n\ndisplay(Markdown(response_conservador.choices[0].message.content))\n\nSí, parece que las nubes están grises. Esto suele indicar que pueden estar cargadas de humedad y que podría llover pronto. ¿Estás esperando algún tipo de clima en particular?\n\n\n\n# Temperatura alta (1.8)\nresponse_creativo = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=1.5\n)\n\nMiremos ahora la respuesta creativa:\n\ndisplay(Markdown(response_creativo.choices[0].message.content))\n\nSí, parecen un poco grises. Cuando las nubes están grises, a menudo significa que pueden estar más cargadas de agua, lo que podría indicar que hay posibilidades de lluvia. ¿Estás esperando alguna precipitación?\n\n\nProbemos ahora con otro ejemplo\n\nprompt = 'Genera un eslogan para una cafeteria en la luna'\n# Temperatura baja (0.2)\nresponse_conservador = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=0.2\n)\n\n# Temperatura alta (1.8)\nresponse_creativo = client.chat.completions.create(\n    model='gpt-4o-mini',\n    messages=[{\n        'role': 'user',\n        'content': prompt\n    }],\n    temperature=1.5\n)\n\nMiramos la respuesta conservadora:\n\ndisplay(Markdown(response_conservador.choices[0].message.content))\n\n“¡Sabor que te eleva! Disfruta un café fuera de este mundo en nuestra cafetería lunar.”\n\n\nMiremos ahora la respuesta creativa:\n\ndisplay(Markdown(response_creativo.choices[0].message.content))\n\n“¡Saborea el universo en cada sorbo en tu cafetería lunar!” 🌙☕️",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  },
  {
    "objectID": "03_Openai_api.html#max_tokens",
    "href": "03_Openai_api.html#max_tokens",
    "title": "Uso de Hiperparámetros",
    "section": "max_tokens",
    "text": "max_tokens",
    "crumbs": [
      "Tutoriales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Uso de Hiperparámetros</span>"
    ]
  }
]